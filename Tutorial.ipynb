{
 "metadata": {
  "name": "",
  "signature": "sha256:771fb23451d8ede2104f4cb8e3ace5114f97c2d9067dc0cadf4ae1fe16352ecd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Getting started\n",
      "## Installing the necessary module\n",
      "\n",
      "You must first install the `inspire` Python module.\n",
      "\n",
      "This can be done using `pip` by running the following command in your terminal:\n",
      "```\n",
      "pip install inspire\n",
      "```\n",
      "\n",
      "You may also run the following command to upgrade to the latest version:\n",
      "```\n",
      "pip install --upgrade inspire\n",
      "```\n",
      "\n",
      "After installing or upgrading the `inspire` module one must **restart the IPython Notebook**.\n",
      "\n",
      "## Importing the necessary modules\n",
      "To start with we will import the modules we are going to use throughout this tutorial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import inspire\n",
      "inspire.BASE_URL='http://localhost:5000'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The setting\n",
      "An evaluation setting is composed of a dataset, a lexicon and several evaluation parameters. A submission will always be tied to a given evaluation setting.  Therefore our first job is to get an evaluation setting to work on.\n",
      "\n",
      "By not passing any parameters we will be getting the default one.  Currently the default setting is a dataset of words in Spanish and a large vocabulary lexicon in IPA encoding."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "setting = inspire.get_evaluation_setting()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The dataset\n",
      "Next we download the dataset, load it, and have a quick peak of what is in it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset_filename = setting.download_dataset()\n",
      "dataset = inspire.load_dataset(dataset_filename)\n",
      "\n",
      "print('There are {} tokens in dataset'.format(len(dataset['tokens'])))\n",
      "\n",
      "inspire.pprint(dataset['tokens']['35541'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our data is a class deriving from a Python dictionary containing an entry named `tokens` with a mapping from a stimulus ID to a stimulus (also named token) presented to a set of listeners.\n",
      "The stimulus itself is represented as a dictionary, with entries for several properties of the stimuli presented: \n",
      "\n",
      "* **type of noise** `noise_type`\n",
      "* **speaker ID** `speaker`\n",
      "* **signal-to-noise ratio** `snr`\n",
      "\n",
      "The filenames of the audios:\n",
      "\n",
      "* **signal wave file** `signal_wav`\n",
      "* **noise wave file** `noise_wav`\n",
      "\n",
      "And the underlying word that was presented as well as those that were reported by the listeners:\n",
      "\n",
      "* **presented word** `speech`\n",
      "\n",
      "## The lexicon\n",
      "Since all the tasks are based on the pronunciations of the words, our next step is to load a lexicon.\n",
      "The lexicon is not in JSON format, it is in a format that HTK understands, therefore parsing it takes a bit more work. Luckily for you we have a written a function to do just that:\n",
      "\n",
      "We will first download the lexicon, load it, and have a quick peak of what is in it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lexicon_filename = setting.download_lexicon()\n",
      "lexicon = inspire.load_lexicon(lexicon_filename)\n",
      "\n",
      "print('There are {} words in the lexicon'.format(len(lexicon)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The lexicon is a subclass of a Python dictionary mapping from a word to a set of pronunciations.  The pronunciations are lists of strings where each string represents a phoneme.\n",
      "\n",
      "To use the lexicon we simply query it as we would do with any other Python dictionary.  Note that the case of the words is ignored when querying the lexicon:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inspire.pprint('Is \"ayuda\" in the lexicon? {}'.format('ayuda' in lexicon))\n",
      "inspire.pprint(lexicon['ayuda'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The submission\n",
      "To make submissions to the INSPIRE Challenge you must have an account on the INSPIRE Challenge: [Click here to register](http://143.167.9.43:5000/register)\n",
      "\n",
      "Note don't use a secure password, since in order to simplify the tasks it may be sent as plain text to the server.\n",
      "The email and password will be used in the following steps to create and submit our predictions.\n",
      "\n",
      "### Preparation of the submission\n",
      "A submission consists of a dictionary data structure containing metadata (information of the participant, the challenge edition and contact details) and the predictions for the stimuli.  The predictions are stored in a data structure similar to that of the dataset (a list of dictionaries, one per stimulus).  Each stimulus dictionary must contain the `token_id` and then a list of task predictions `task_prediction` each task prediction is a dictionary containing a `task` property indicating what task it is solving and the `prediction` which is dictionary whose form depends on the task.\n",
      "\n",
      "In order to avoid errors when creating the participation data structure, we have built a Python class that eases the job."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission = inspire.Submission(email='dummy@email.com', \n",
      "                                evaluation_setting=setting)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Adding the predictions of the tasks\n",
      "We iterate over the dataset and for each presented word we query it's pronunciations, and arbitrarily select one.\n",
      "We will then produce the predictions for each of the tasks.  In this simple baseline random guessing scenario we will follow the same predcition strategy independently of the token:\n",
      "\n",
      "* **where task** For the phoneme positions we predict a 50% chance of observing a confusion. We predict a 1% chance of confusion at the inter-phoneme positions and a 30% chance of confusion at the positions before and after the utterance.\n",
      "* **what task** We only provide predictions for the phoneme positions, we do not provide predictions for inter-phoneme positions. We predict a 50% chance of not observing a confusion (the presented phoneme will remain) and a 5% of deleting the phoneme.\n",
      "* **full task** We predict a 10% of not observing a confusion (the ellicited pronunciation being reported)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Iterate over all the stimuli in our dataset\n",
      "for token_id, token  in dataset['tokens'].items()[:10]:\n",
      "    word = token['speech']\n",
      "    \n",
      "    # Lexicon may contain multiple pronunciations\n",
      "    pronunciations = lexicon[word.upper()]\n",
      "    \n",
      "    # Here we arbitrarily select the first one\n",
      "    pronunciation = pronunciations[0]\n",
      "    \n",
      "    # Get a list of phonemes from the space separated pronunciation of the lexicon\n",
      "    phonemes = pronunciation\n",
      "    \n",
      "    # Possible indices of confusions\n",
      "    # are the number of phonemes plus\n",
      "    # the number of positions around phonemes\n",
      "    index_count = len(phonemes)*2 + 1\n",
      "    \n",
      "    confusion_probabilities = np.zeros(index_count)\n",
      "\n",
      "    # Our random guess for the Where task assumes:\n",
      "    #  - a 30% chance of finding a confusion at all phoneme positions (substitutions or removals)\n",
      "    confusion_probabilities[1::2] = 0.3\n",
      "    \n",
      "    #  - a 1% chance of finding an insertion between all phoneme positions (insertions)\n",
      "    confusion_probabilities[2:-2:2] = 0.01\n",
      "    \n",
      "    #  - a 50% chance of finding insertions of phonemes at beginning and end of words (insertions)\n",
      "    confusion_probabilities[0] = 0.5\n",
      "    confusion_probabilities[-1] = 0.5\n",
      "            \n",
      "    submission.where_task(token_id, confusion_probabilities)\n",
      "    \n",
      "    # Our random guess for the What task assumes:\n",
      "    # Phonemes are represented as strings\n",
      "    # Sequence of phonemes are space joined strings\n",
      "    # A removal is represented as an empty string\n",
      "    for phoneme_index, phoneme in enumerate(phonemes):\n",
      "        index = phoneme_index * 2 + 1\n",
      "        \n",
      "        #  - a 50% chance of not changing the phoneme\n",
      "        submission.what_task(token_id, index, phoneme, 0.5)\n",
      "\n",
      "        #  - a 5% chance of phoneme removal\n",
      "        submission.what_task(token_id, index, '', 0.05)\n",
      "        \n",
      "    # Our random guess for the Full task assumes:\n",
      "    #  - a 10% chance of reporting the pronunciation of the presented utterance\n",
      "    submission.full_task(token_id, ' '.join(pronunciation), 0.1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Once the submission has been created we can print the predictions of a given token.\n",
      "This is also useful to understand the JSON format of a submission."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inspire.pprint(submission['tokens']['35541'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'full': {u'p e k \u02c8e \u0272 o s': 0.1},\n",
        " u'what': {'1': {'': 0.05, u'p': 0.5},\n",
        "           '11': {'': 0.05, u'o': 0.5},\n",
        "           '13': {'': 0.05, u's': 0.5},\n",
        "           '3': {'': 0.05, u'e': 0.5},\n",
        "           '5': {'': 0.05, u'k': 0.5},\n",
        "           '7': {'': 0.05, u'\u02c8e': 0.5},\n",
        "           '9': {'': 0.05, u'\u0272': 0.5}},\n",
        " u'where': [0.5,\n",
        "            0.29999999999999999,\n",
        "            0.01,\n",
        "            0.29999999999999999,\n",
        "            0.01,\n",
        "            0.29999999999999999,\n",
        "            0.01,\n",
        "            0.29999999999999999,\n",
        "            0.01,\n",
        "            0.29999999999999999,\n",
        "            0.01,\n",
        "            0.29999999999999999,\n",
        "            0.01,\n",
        "            0.29999999999999999,\n",
        "            0.5]}\n"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also save the submission as a JSON file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "submission.save('submission_random_guess.json')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 74
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evaluating before submitting\n",
      "\n",
      "Sometimes we might not want to submit, and simply evaluate a submission.  In that case we may call `evaluate()`.\n",
      "\n",
      "The evaluation **may take some time**, especially if the submission covers all tasks and all tokens.\n",
      "\n",
      "If you want quicker results only perform predictions on a subset of the tokens and/or the tasks."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = submission.evaluate(password='dummypassword')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 81
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inspire.pprint(results['evaluation']['where']['token_averaged'])\n",
      "inspire.pprint(results['evaluation']['what']['token_averaged'])\n",
      "inspire.pprint(results['evaluation']['full']['token_averaged'])\n",
      "results.items()[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-4.330608619221855\n",
        "-24.06466661141278\n",
        "-51.24983838293326\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 82,
       "text": [
        "(u'evaluation',\n",
        " {u'full': {u'token_averaged': -51.24983838293326,\n",
        "   u'tokens': {u'11540': {u'token': -57.85130989696984},\n",
        "    u'13733': {u'token': -56.975841159615925},\n",
        "    u'16078': {u'token': -47.75753261799058},\n",
        "    u'16079': {u'token': -55.36640324718182},\n",
        "    u'22460': {u'token': -47.40085767405184},\n",
        "    u'26377': {u'token': -49.70344276704588},\n",
        "    u'32230': {u'token': -44.53865679312237},\n",
        "    u'32231': {u'token': -51.6775237930679},\n",
        "    u'35541': {u'token': -44.94412190123054,\n",
        "     u'trial_count': 15,\n",
        "     u'trials': {u'b j \\u02c8a x a s': 1,\n",
        "      u'p e k \\u02c8e n a': 1,\n",
        "      u'p e k \\u02c8e n o': 3,\n",
        "      u'p e k \\u02c8e n o s': 2,\n",
        "      u'p e k \\u02c8e \\u0272 a s': 3,\n",
        "      u'p e k \\u02c8e \\u0272 o': 3,\n",
        "      u'p e k \\u02c8e \\u0272 o s': 1,\n",
        "      u'p e s t \\u02c8a n a s': 1}},\n",
        "    u'35549': {u'token': -56.28269397905599}}},\n",
        "  u'what': {u'token_averaged': -24.06466661141278,\n",
        "   u'tokens': {u'11540': {u'phoneme': [nan,\n",
        "      -56.59954642880754,\n",
        "      nan,\n",
        "      -10.39720770839918,\n",
        "      nan,\n",
        "      -10.39720770839918,\n",
        "      nan,\n",
        "      -42.363066576199145,\n",
        "      nan,\n",
        "      -42.363066576199145],\n",
        "     u'token': -32.42401899960084},\n",
        "    u'13733': {u'phoneme': [nan,\n",
        "      -10.39720770839918,\n",
        "      nan,\n",
        "      -10.39720770839918,\n",
        "      nan,\n",
        "      -10.39720770839918,\n",
        "      nan,\n",
        "      -58.20898434124165,\n",
        "      nan,\n",
        "      -14.914367017064556],\n",
        "     u'token': -20.86299489670075},\n",
        "    u'16078': {u'phoneme': [nan,\n",
        "      -40.585811793173974,\n",
        "      nan,\n",
        "      -44.49783479860213,\n",
        "      nan,\n",
        "      -40.80895534448818,\n",
        "      nan,\n",
        "      -40.80895534448818,\n",
        "      nan,\n",
        "      -28.338917153123546,\n",
        "      nan,\n",
        "      -25.456513564876563,\n",
        "      nan,\n",
        "      -39.19951743205409],\n",
        "     u'token': -37.099500775829526},\n",
        "    u'16079': {u'phoneme': [nan,\n",
        "      -12.388638372756304,\n",
        "      nan,\n",
        "      -33.28055957573285,\n",
        "      nan,\n",
        "      -15.830657748938712,\n",
        "      nan,\n",
        "      -12.388638372756304,\n",
        "      nan,\n",
        "      -38.578876942280885,\n",
        "      nan,\n",
        "      -11.184665568430365,\n",
        "      nan,\n",
        "      -42.49089994770903],\n",
        "     u'token': -23.734705218372063},\n",
        "    u'22460': {u'phoneme': [nan,\n",
        "      -15.512204017820176,\n",
        "      nan,\n",
        "      -13.122607547836502,\n",
        "      nan,\n",
        "      -42.57254393674954],\n",
        "     u'token': -23.735785167468737},\n",
        "    u'26377': {u'phoneme': [nan,\n",
        "      -34.99535800382478,\n",
        "      nan,\n",
        "      -11.601180512725115,\n",
        "      nan,\n",
        "      -39.31284611736108,\n",
        "      nan,\n",
        "      -38.90738100925292,\n",
        "      nan,\n",
        "      -13.902766105386082,\n",
        "      nan,\n",
        "      -10.39720770839918],\n",
        "     u'token': -24.85278990949153},\n",
        "    u'32230': {u'phoneme': [nan,\n",
        "      -37.01026102436704,\n",
        "      nan,\n",
        "      -12.874146188538006,\n",
        "      nan,\n",
        "      -11.601180512725115,\n",
        "      nan,\n",
        "      -34.93081948268721,\n",
        "      nan,\n",
        "      -14.22121983650461,\n",
        "      nan,\n",
        "      -15.648336192144757],\n",
        "     u'token': -21.047660539494455},\n",
        "    u'32231': {u'phoneme': [nan,\n",
        "      -13.122607547836502,\n",
        "      nan,\n",
        "      -15.648336192144757,\n",
        "      nan,\n",
        "      -12.61178192407051,\n",
        "      nan,\n",
        "      -10.39720770839918,\n",
        "      nan,\n",
        "      -9.991742600291014,\n",
        "      nan,\n",
        "      -43.812655787691355,\n",
        "      nan,\n",
        "      -11.184665568430365,\n",
        "      nan,\n",
        "      -35.583144668726895],\n",
        "     u'token': -19.044017749698824},\n",
        "    u'35541': {u'phoneme': [nan,\n",
        "      -9.991742600291014,\n",
        "      nan,\n",
        "      -11.601180512725115,\n",
        "      nan,\n",
        "      -11.264708276103903,\n",
        "      nan,\n",
        "      -11.264708276103903,\n",
        "      nan,\n",
        "      -24.58104482752266,\n",
        "      nan,\n",
        "      -18.03793266212843,\n",
        "      nan,\n",
        "      -17.40932400270606],\n",
        "     u'token': -14.878663022511583,\n",
        "     u'trial_count': 15,\n",
        "     u'trials': {u'1': {u'': 1, u'p': 14},\n",
        "      u'11': {u'': 2, u'a': 3, u'n': 1, u'o': 9},\n",
        "      u'13': {u'': 6, u'a': 1, u's': 8},\n",
        "      u'3': {u'b': 1, u'e': 14},\n",
        "      u'5': {u'': 1, u'k': 13, u's': 1},\n",
        "      u'7': {u'': 1, u'\\u02c8a': 1, u'\\u02c8e': 13},\n",
        "      u'9': {u'': 2, u'n': 5, u'\\u0272': 7, u'\\u02c8a': 1}}},\n",
        "    u'35549': {u'phoneme': [nan,\n",
        "      -12.874146188538003,\n",
        "      nan,\n",
        "      -10.39720770839918,\n",
        "      nan,\n",
        "      -11.184665568430365,\n",
        "      nan,\n",
        "      -40.18831485471499,\n",
        "      nan,\n",
        "      -40.18831485471499],\n",
        "     u'token': -22.966529834959506}}},\n",
        "  u'where': {u'token_averaged': -4.330608619221855,\n",
        "   u'tokens': {u'11540': {u'phoneme': [-10.39720770839918,\n",
        "      -11.711035993957106,\n",
        "      -0.15075503780252164,\n",
        "      -5.350124159080985,\n",
        "      -0.15075503780252164,\n",
        "      -5.350124159080985,\n",
        "      -0.15075503780252164,\n",
        "      -18.059592064889042,\n",
        "      -0.15075503780252164,\n",
        "      -18.059592064889042,\n",
        "      -10.39720770839918],\n",
        "     u'token': -7.2661730918096},\n",
        "    u'13733': {u'phoneme': [-5.74324735824165,\n",
        "      -5.350124159080985,\n",
        "      -0.15075503780252164,\n",
        "      -5.350124159080985,\n",
        "      -0.15075503780252164,\n",
        "      -5.350124159080985,\n",
        "      -0.15075503780252164,\n",
        "      -14.504244003399627,\n",
        "      -0.15075503780252164,\n",
        "      -1.7717203212916415,\n",
        "      -10.39720770839918],\n",
        "     u'token': -4.460892001798649},\n",
        "    u'16078': {u'phoneme': [-1.8790150166498556,\n",
        "      -14.504244003399627,\n",
        "      -0.15075503780252164,\n",
        "      -18.059592064889042,\n",
        "      -2.0378246868349006,\n",
        "      -14.504244003399627,\n",
        "      -0.15075503780252164,\n",
        "      -14.504244003399627,\n",
        "      -0.15075503780252164,\n",
        "      -4.457612210816495,\n",
        "      -0.15075503780252164,\n",
        "      -2.5117020617611816,\n",
        "      -0.15075503780252164,\n",
        "      -9.397401064776476,\n",
        "      -1.8790150166498556],\n",
        "     u'token': -5.6325779547726205},\n",
        "    u'16079': {u'phoneme': [-10.39720770839918,\n",
        "      -1.520405893010738,\n",
        "      -0.15075503780252164,\n",
        "      -4.457612210816495,\n",
        "      -0.15075503780252164,\n",
        "      -1.520405893010738,\n",
        "      -0.15075503780252164,\n",
        "      -1.520405893010738,\n",
        "      -0.15075503780252164,\n",
        "      -9.397401064776476,\n",
        "      -0.15075503780252164,\n",
        "      -1.7717203212916415,\n",
        "      -0.15075503780252164,\n",
        "      -18.059592064889042,\n",
        "      -7.689157507296969],\n",
        "     u'token': -3.81589591888781},\n",
        "    u'22460': {u'phoneme': [-4.2769102894482245,\n",
        "      -2.5117020617611816,\n",
        "      -0.15075503780252164,\n",
        "      -1.5792463930336726,\n",
        "      -0.15075503780252164,\n",
        "      -11.711035993957106,\n",
        "      -3.178298000780118],\n",
        "     u'token': -3.365528973512192},\n",
        "    u'26377': {u'phoneme': [-5.74324735824165,\n",
        "      -14.504244003399627,\n",
        "      -0.15075503780252164,\n",
        "      -2.390759529697863,\n",
        "      -0.15075503780252164,\n",
        "      -11.711035993957106,\n",
        "      -2.0378246868349006,\n",
        "      -18.059592064889042,\n",
        "      -0.15075503780252164,\n",
        "      -1.5792463930336726,\n",
        "      -0.15075503780252164,\n",
        "      -5.350124159080985,\n",
        "      -10.39720770839918],\n",
        "     u'token': -5.567407849903391},\n",
        "    u'32230': {u'phoneme': [-4.2769102894482245,\n",
        "      -5.815735694969691,\n",
        "      -0.15075503780252164,\n",
        "      -2.390759529697863,\n",
        "      -0.15075503780252164,\n",
        "      -3.489371818365978,\n",
        "      -0.15075503780252164,\n",
        "      -5.815735694969691,\n",
        "      -0.15075503780252164,\n",
        "      -1.7717203212916415,\n",
        "      -0.15075503780252164,\n",
        "      -1.520405893010738,\n",
        "      -3.178298000780118],\n",
        "     u'token': -2.231747110118966},\n",
        "    u'32231': {u'phoneme': [-7.689157507296969,\n",
        "      -1.520405893010738,\n",
        "      -0.15075503780252164,\n",
        "      -1.520405893010738,\n",
        "      -0.15075503780252164,\n",
        "      -1.7717203212916415,\n",
        "      -0.15075503780252164,\n",
        "      -5.350124159080985,\n",
        "      -0.15075503780252164,\n",
        "      -3.489371818365978,\n",
        "      -0.15075503780252164,\n",
        "      -11.711035993957106,\n",
        "      -0.15075503780252164,\n",
        "      -1.7717203212916415,\n",
        "      -0.15075503780252164,\n",
        "      -14.504244003399627,\n",
        "      -5.74324735824165],\n",
        "     u'token': -3.301571678444983},\n",
        "    u'35541': {u'phoneme': [-10.39720770839918,\n",
        "      -3.489371818365978,\n",
        "      -0.15075503780252164,\n",
        "      -3.489371818365978,\n",
        "      -0.15075503780252164,\n",
        "      -2.390759529697863,\n",
        "      -0.15075503780252164,\n",
        "      -2.390759529697863,\n",
        "      -0.15075503780252164,\n",
        "      -3.358999922148385,\n",
        "      -2.0378246868349006,\n",
        "      -1.9157186296548847,\n",
        "      -0.15075503780252164,\n",
        "      -2.5117020617611816,\n",
        "      -10.39720770839918],\n",
        "     u'token': -2.8755132401558665,\n",
        "     u'trial_count': 15.0,\n",
        "     u'trials': [0.0,\n",
        "      1.0,\n",
        "      0.0,\n",
        "      1.0,\n",
        "      0.0,\n",
        "      2.0,\n",
        "      0.0,\n",
        "      2.0,\n",
        "      0.0,\n",
        "      8.0,\n",
        "      1.0,\n",
        "      6.0,\n",
        "      0.0,\n",
        "      7.0,\n",
        "      0.0]},\n",
        "    u'35549': {u'phoneme': [-4.2769102894482245,\n",
        "      -1.7717203212916415,\n",
        "      -0.15075503780252164,\n",
        "      -2.390759529697863,\n",
        "      -0.15075503780252164,\n",
        "      -1.7717203212916415,\n",
        "      -0.15075503780252164,\n",
        "      -18.059592064889042,\n",
        "      -0.15075503780252164,\n",
        "      -18.059592064889042,\n",
        "      -5.74324735824165],\n",
        "     u'token': -4.7887783728144715}}}})"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Sending in the submission\n",
      "\n",
      "The final step is to send the submission. This will save a copy of the submission in the server and return the evaluation results.\n",
      "\n",
      "To submit we simply call the submit function of the submission object that we have created.\n",
      "The email that we have used when creating the submission class is the one that will be used to login to the server.\n",
      "We must also supply the password that we used when we registered to the INSPIRE Challenge website."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = submission.submit(password='dummypassword')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inspire.pprint(results['evaluation']['where']['token_averaged'])\n",
      "inspire.pprint(results['evaluation']['what']['token_averaged'])\n",
      "inspire.pprint(results['evaluation']['full']['token_averaged'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "-4.330608619221855\n",
        "-24.06466661141278\n",
        "-51.24983838293326\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}